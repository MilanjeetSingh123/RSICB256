{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = r'C:\\Users\\Milanjeet Singh\\Desktop\\New folder (3)\\RSI-CB256\\Train'\n",
    "Validation = r'C:\\Users\\Milanjeet Singh\\Desktop\\New folder (3)\\RSI-CB256\\Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating image data from the images\n",
    "Train_Generator = ImageDataGenerator(rescale=1/255.)\n",
    "Valid_Generator = ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24747 images belonging to 35 classes.\n",
      "Found 1750 images belonging to 35 classes.\n"
     ]
    }
   ],
   "source": [
    "Train_Data = Train_Generator.flow_from_directory(Train,target_size=(32,32),batch_size=64,class_mode='categorical')\n",
    "Valid_Data = Valid_Generator.flow_from_directory(Validation,target_size=(32,32),batch_size=64,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 20s 1us/step\n"
     ]
    }
   ],
   "source": [
    "Base_Model = DenseNet121(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(Base_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Dense(4096,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Dense(2048,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Dense(1024,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Dense(512,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Dense(256,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.add(layers.Dense(35,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Functional)     (None, 1, 1, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 35)                8995      \n",
      "=================================================================\n",
      "Total params: 22,389,859\n",
      "Trainable params: 22,306,211\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.compile(optimizer = optimizers.Adam(learning_rate=0.001) , loss= 'categorical_crossentropy',metrics='categorical_accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet121\n",
    "Accuracy : 97\n",
    "Epochs : 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "386/386 [==============================] - 58s 151ms/step - loss: 0.1490 - categorical_accuracy: 0.9628 - val_loss: 0.5112 - val_categorical_accuracy: 0.8565\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.1253 - categorical_accuracy: 0.9683 - val_loss: 0.7133 - val_categorical_accuracy: 0.8333\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 54s 140ms/step - loss: 0.1365 - categorical_accuracy: 0.9665 - val_loss: 0.4062 - val_categorical_accuracy: 0.8929\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 53s 137ms/step - loss: 0.1692 - categorical_accuracy: 0.9605 - val_loss: 0.3988 - val_categorical_accuracy: 0.8964\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 59s 153ms/step - loss: 0.1766 - categorical_accuracy: 0.9609 - val_loss: 0.1373 - val_categorical_accuracy: 0.9595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a4e758d00>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(Train_Data,steps_per_epoch=386,epochs=15,validation_data = Valid_Data, validation_steps=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet169\n",
    "Den169 = DenseNet169(include_top = False,weights = 'imagenet',input_shape=(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flat_Model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flat_Model.add(layers.Dense(4096,activation='relu'))\n",
    "Flat_Model.add(layers.Dense(2048,activation='relu'))\n",
    "Flat_Model.add(layers.Dense(1024,activation='relu'))\n",
    "Flat_Model.add(layers.Dense(512,activation='relu'))\n",
    "Flat_Model.add(layers.Dense(256,activation='relu'))\n",
    "Flat_Model.add(layers.Dense(35,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Dense169 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Dense169.add(Den169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Dense169.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Dense169.add(Flat_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Dense169.compile(optimizer = optimizers.Adam(learning_rate=0.0001) , loss= 'categorical_crossentropy',metrics='categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet169 (Functional)     (None, 1, 1, 1664)        12642880  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 35)                17973795  \n",
      "=================================================================\n",
      "Total params: 30,616,675\n",
      "Trainable params: 30,458,275\n",
      "Non-trainable params: 158,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_Dense169.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "386/386 [==============================] - 213s 472ms/step - loss: 0.6674 - categorical_accuracy: 0.8255 - val_loss: 0.3755 - val_categorical_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "386/386 [==============================] - 84s 217ms/step - loss: 0.1422 - categorical_accuracy: 0.9598 - val_loss: 0.0787 - val_categorical_accuracy: 0.9740\n",
      "Epoch 3/10\n",
      "386/386 [==============================] - 72s 186ms/step - loss: 0.1035 - categorical_accuracy: 0.9702 - val_loss: 0.0744 - val_categorical_accuracy: 0.9803\n",
      "Epoch 4/10\n",
      "386/386 [==============================] - 71s 183ms/step - loss: 0.0744 - categorical_accuracy: 0.9785 - val_loss: 0.0603 - val_categorical_accuracy: 0.9815\n",
      "Epoch 5/10\n",
      "386/386 [==============================] - 68s 175ms/step - loss: 0.0597 - categorical_accuracy: 0.9835 - val_loss: 0.0280 - val_categorical_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "386/386 [==============================] - 58s 150ms/step - loss: 0.0564 - categorical_accuracy: 0.9839 - val_loss: 0.0366 - val_categorical_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "386/386 [==============================] - 55s 141ms/step - loss: 0.0556 - categorical_accuracy: 0.9848 - val_loss: 0.0240 - val_categorical_accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "386/386 [==============================] - 62s 160ms/step - loss: 0.0457 - categorical_accuracy: 0.9885 - val_loss: 0.0176 - val_categorical_accuracy: 0.9936\n",
      "Epoch 9/10\n",
      "386/386 [==============================] - 61s 158ms/step - loss: 0.0450 - categorical_accuracy: 0.9878 - val_loss: 0.0704 - val_categorical_accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "386/386 [==============================] - 57s 147ms/step - loss: 0.0379 - categorical_accuracy: 0.9890 - val_loss: 0.0500 - val_categorical_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20707604e80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Dense169.fit(Train_Data,steps_per_epoch=386,epochs=10,validation_data = Valid_Data, validation_steps=27)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet169 : \n",
    "Accuracy : ~99\n",
    "Epochs : 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.save(r'C:\\Users\\Milanjeet Singh\\Desktop\\New folder (3)\\Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.save_weights(\"Model_Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "725a7f0c4179cfd551ad76b57901185fa78e26d73a2072955fb6623e1fe5c9ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
